# Reu TPF 30-08-2023

## Paralelización, Offloading a disco

Podemos encarar por:
- Paralelizar algunos algoritmos + engine de paralelización
- Paralelizar muchos algoritmos (y agregar otros)

Idealmente podriamos: Dividir data en n partes. n-1 en disco, 1 en mem, laburar en baches.
Si ademas el algoritmo puede laburar las particiones en paralelo, es facil meter Dask (ahi tenemos ambas cosas, paralelizacion y offloading a disco). 
Si las particiones son pequeñas, tmbn se podría hacer distribuido -> out of core processing.


## POCs

- Tomar algoritmos que puedan ser paralelizables y hacer la prueba. Trackear tiempo.
- Profilear

## Tracking de tiempo

- Trackear el tiempo invertido en cada cosa. Buscar alguna herramienta ([Watson](https://tailordev.github.io/Watson/)).


## Profiling

- Podemos ver como hacen los tipos de networkx sus benchmarks de performance para ver que profilers utilizan y usar esos mismos (para tener mas affinity).
- Tambien podemos optar por las herramientas usuales (`cProfile`, `lineprof`).


## Issues con codear en nx-parallel (camino de paralelización)

- Podría ser peligroso tener en dos repos distintos el código (si cambian los métodos privados en NetworkX, se rompe nx-parallel)

